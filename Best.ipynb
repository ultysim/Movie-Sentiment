{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as k\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import GRU, Dense, Activation, Embedding, Input, Dropout, LSTM\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, GlobalMaxPooling1D, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.tsv',sep='\\t')\n",
    "test = pd.read_csv('test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17780 unique tokens.\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#Try with less words:\n",
    "MAX_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "texts = data['Phrase'].values\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "tokenizer.fit_on_texts(test['Phrase'].values)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.'+str(EMBEDDING_DIM)+'d.txt',encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "#Pad the sequences to the max sequence length\n",
    "MAX_SEQUENCE_LENGTH = max([len(i) for i in sequences])\n",
    "x = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y = np_utils.to_categorical(data['Sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BEST MODEL\n",
    "UNITS = 64\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,EMBEDDING_DIM,weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH,mask_zero=True))\n",
    "model.add(LSTM(UNITS,recurrent_dropout=0.2,dropout=0.2))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x, y, batch_size=64, epochs=4, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = model.fit(x, y, batch_size=64, epochs=1, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h.history['val_acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "\n",
    "def data():\n",
    "    MAX_WORDS = 20000\n",
    "    EMBEDDING_DIM = 100\n",
    "    \n",
    "    data = pandas.read_csv('train.tsv',sep='\\t')\n",
    "    test = pandas.read_csv('test.tsv',sep='\\t')\n",
    "\n",
    "    texts = data['Phrase'].values\n",
    "    tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    tokenizer.fit_on_texts(test['Phrase'].values)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "    embeddings_index = {}\n",
    "    f = open('glove.6B.'+str(EMBEDDING_DIM)+'d.txt',encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = numpy.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "    embedding_matrix = numpy.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    #Pad the sequences to the max sequence length\n",
    "    MAX_SEQUENCE_LENGTH = max([len(i) for i in sequences])\n",
    "    x = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    y = np_utils.to_categorical(data['Sentiment'].values)\n",
    "    return x, y, word_index, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH\n",
    "\n",
    "def model(x, y, word_index, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH):\n",
    "# BEST MODEL\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1,EMBEDDING_DIM,weights=[embedding_matrix], \n",
    "                        input_length=MAX_SEQUENCE_LENGTH,mask_zero=True))\n",
    "    \n",
    "    model.add(LSTM({{choice([128,256,512])}},recurrent_dropout={{choice([0.2, 0.4])}},dropout={{choice([0.2, 0.4])}}))\n",
    "    \n",
    "    model.add(Dense({{choice([128,256,512])}},activation='relu'))\n",
    "    \n",
    "    model.add(Dropout({{choice([0.2,0.4])}}))\n",
    "    \n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer={{choice(['adam','rmsprop'])}}, metrics=['accuracy'])\n",
    "    \n",
    "    es = EarlyStopping(patience=2)\n",
    "    \n",
    "    history = model.fit(x, y, batch_size=128, epochs=5, verbose=2, validation_split=0.2,callbacks=[es])\n",
    "    \n",
    "    acc = max(history.history['val_acc'])\n",
    "    \n",
    "    print('Test accuracy:', acc)\n",
    "    \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_t = pd.read_csv('train.tsv',sep='\\t')\n",
    "test_t = pd.read_csv('test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import GRU, Dense, Activation, Embedding, Input, Dropout, LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Conv1D, MaxPooling1D, Flatten, GlobalMaxPooling1D, BatchNormalization\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing.sequence import pad_sequences\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing.text import Tokenizer, one_hot\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'LSTM': hp.choice('LSTM', [64,128,256,512]),\n",
      "        'recurrent_dropout': hp.choice('recurrent_dropout', [0.2, 0.4]),\n",
      "        'recurrent_dropout_1': hp.choice('recurrent_dropout_1', [0.2, 0.4]),\n",
      "        'LSTM_1': hp.choice('LSTM_1', [64,128,256,512]),\n",
      "        'Dropout': hp.choice('Dropout', [0.2,0.4]),\n",
      "        'optimizer': hp.choice('optimizer', ['adam','rmsprop']),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: MAX_WORDS = 20000\n",
      "   3: EMBEDDING_DIM = 100\n",
      "   4: \n",
      "   5: data = pandas.read_csv('train.tsv',sep='\\t')\n",
      "   6: test = pandas.read_csv('test.tsv',sep='\\t')\n",
      "   7: \n",
      "   8: texts = data['Phrase'].values\n",
      "   9: tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
      "  10: tokenizer.fit_on_texts(texts)\n",
      "  11: tokenizer.fit_on_texts(test['Phrase'].values)\n",
      "  12: sequences = tokenizer.texts_to_sequences(texts)\n",
      "  13: \n",
      "  14: word_index = tokenizer.word_index\n",
      "  15: print('Found %s unique tokens.' % len(word_index))\n",
      "  16: \n",
      "  17: embeddings_index = {}\n",
      "  18: f = open('glove.6B.'+str(EMBEDDING_DIM)+'d.txt',encoding=\"utf8\")\n",
      "  19: for line in f:\n",
      "  20:     values = line.split()\n",
      "  21:     word = values[0]\n",
      "  22:     coefs = numpy.asarray(values[1:], dtype='float32')\n",
      "  23:     embeddings_index[word] = coefs\n",
      "  24: f.close()\n",
      "  25: \n",
      "  26: print('Found %s word vectors.' % len(embeddings_index))\n",
      "  27: \n",
      "  28: \n",
      "  29: embedding_matrix = numpy.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
      "  30: for word, i in word_index.items():\n",
      "  31:     embedding_vector = embeddings_index.get(word)\n",
      "  32:     if embedding_vector is not None:\n",
      "  33:         # words not found in embedding index will be all-zeros.\n",
      "  34:         embedding_matrix[i] = embedding_vector\n",
      "  35: \n",
      "  36: #Pad the sequences to the max sequence length\n",
      "  37: MAX_SEQUENCE_LENGTH = max([len(i) for i in sequences])\n",
      "  38: x = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
      "  39: y = np_utils.to_categorical(data['Sentiment'].values)\n",
      "  40: \n",
      "  41: \n",
      "  42: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "  1: def keras_fmin_fnct(space):\n",
      "  2: \n",
      "  3:     model = Sequential()\n",
      "  4:     model.add(Embedding(len(word_index) + 1,EMBEDDING_DIM,weights=[embedding_matrix], \n",
      "  5:                         input_length=MAX_SEQUENCE_LENGTH,mask_zero=True))\n",
      "  6:     \n",
      "  7:     model.add(LSTM(space['LSTM'],recurrent_dropout=space['recurrent_dropout'],dropout=space['recurrent_dropout_1']))\n",
      "  8:     \n",
      "  9:     model.add(Dense(space['LSTM_1'],activation='relu'))\n",
      " 10:     \n",
      " 11:     model.add(Dropout(space['Dropout']))\n",
      " 12:     \n",
      " 13:     model.add(Dense(5,activation='softmax'))\n",
      " 14:     \n",
      " 15:     model.compile(loss='categorical_crossentropy', optimizer=space['optimizer'], metrics=['accuracy'])\n",
      " 16:     \n",
      " 17:     es = EarlyStopping(patience=2)\n",
      " 18:     \n",
      " 19:     history = model.fit(x, y, batch_size=128, epochs=5, verbose=2, validation_split=0.2,callbacks=[es])\n",
      " 20:     \n",
      " 21:     acc = max(history.history['val_acc'])\n",
      " 22:     \n",
      " 23:     print('Test accuracy:', acc)\n",
      " 24:     \n",
      " 25:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      " 26: \n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "401s - loss: 0.9391 - acc: 0.6125 - val_loss: 0.9175 - val_acc: 0.6197\n",
      "Epoch 2/5\n",
      "391s - loss: 0.7806 - acc: 0.6742 - val_loss: 0.9226 - val_acc: 0.6189\n",
      "Epoch 3/5\n",
      "388s - loss: 0.7161 - acc: 0.7013 - val_loss: 0.9314 - val_acc: 0.6253\n",
      "Epoch 4/5\n",
      "410s - loss: 0.6716 - acc: 0.7166 - val_loss: 0.9438 - val_acc: 0.6229\n",
      "Test accuracy: 0.625272331216\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "237s - loss: 1.0283 - acc: 0.5794 - val_loss: 0.9757 - val_acc: 0.5902\n",
      "Epoch 2/5\n",
      "229s - loss: 0.8864 - acc: 0.6339 - val_loss: 0.9186 - val_acc: 0.6172\n",
      "Epoch 3/5\n",
      "227s - loss: 0.8327 - acc: 0.6567 - val_loss: 0.9229 - val_acc: 0.6140\n",
      "Epoch 4/5\n",
      "229s - loss: 0.7994 - acc: 0.6703 - val_loss: 0.9201 - val_acc: 0.6231\n",
      "Epoch 5/5\n",
      "224s - loss: 0.7738 - acc: 0.6838 - val_loss: 0.9210 - val_acc: 0.6183\n",
      "Test accuracy: 0.623093682146\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "285s - loss: 0.9935 - acc: 0.5924 - val_loss: 0.9625 - val_acc: 0.5997\n",
      "Epoch 2/5\n",
      "345s - loss: 0.8552 - acc: 0.6465 - val_loss: 0.9171 - val_acc: 0.6170\n",
      "Epoch 3/5\n",
      "350s - loss: 0.7974 - acc: 0.6715 - val_loss: 0.9276 - val_acc: 0.6182\n",
      "Epoch 4/5\n",
      "324s - loss: 0.7624 - acc: 0.6875 - val_loss: 0.9283 - val_acc: 0.6155\n",
      "Epoch 5/5\n",
      "310s - loss: 0.7350 - acc: 0.6985 - val_loss: 0.9171 - val_acc: 0.6283\n",
      "Test accuracy: 0.6283480714\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "460s - loss: 0.9781 - acc: 0.5980 - val_loss: 0.9438 - val_acc: 0.6054\n",
      "Epoch 2/5\n",
      "447s - loss: 0.8399 - acc: 0.6523 - val_loss: 0.9182 - val_acc: 0.6147\n",
      "Epoch 3/5\n",
      "435s - loss: 0.7823 - acc: 0.6769 - val_loss: 0.9368 - val_acc: 0.6077\n",
      "Epoch 4/5\n",
      "359s - loss: 0.7428 - acc: 0.6955 - val_loss: 0.9182 - val_acc: 0.6267\n",
      "Epoch 5/5\n",
      "354s - loss: 0.7152 - acc: 0.7070 - val_loss: 0.9269 - val_acc: 0.6282\n",
      "Test accuracy: 0.628155837521\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "235s - loss: 0.9352 - acc: 0.6145 - val_loss: 0.9188 - val_acc: 0.6183\n",
      "Epoch 2/5\n",
      "233s - loss: 0.7802 - acc: 0.6739 - val_loss: 0.9238 - val_acc: 0.6243\n",
      "Epoch 3/5\n",
      "233s - loss: 0.7173 - acc: 0.6999 - val_loss: 0.9236 - val_acc: 0.6210\n",
      "Epoch 4/5\n",
      "233s - loss: 0.6736 - acc: 0.7156 - val_loss: 0.9389 - val_acc: 0.6240\n",
      "Test accuracy: 0.624311162435\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "356s - loss: 0.9791 - acc: 0.5989 - val_loss: 0.9205 - val_acc: 0.6167\n",
      "Epoch 2/5\n",
      "353s - loss: 0.8181 - acc: 0.6589 - val_loss: 0.9134 - val_acc: 0.6175\n",
      "Epoch 3/5\n",
      "354s - loss: 0.7575 - acc: 0.6835 - val_loss: 0.9109 - val_acc: 0.6221\n",
      "Epoch 4/5\n",
      "354s - loss: 0.7146 - acc: 0.7003 - val_loss: 0.9246 - val_acc: 0.6259\n",
      "Epoch 5/5\n",
      "354s - loss: 0.6834 - acc: 0.7132 - val_loss: 0.9380 - val_acc: 0.6201\n",
      "Test accuracy: 0.625945149363\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "355s - loss: 0.9875 - acc: 0.5939 - val_loss: 0.9211 - val_acc: 0.6143\n",
      "Epoch 2/5\n",
      "352s - loss: 0.8225 - acc: 0.6571 - val_loss: 0.9113 - val_acc: 0.6231\n",
      "Epoch 3/5\n",
      "353s - loss: 0.7629 - acc: 0.6822 - val_loss: 0.9171 - val_acc: 0.6211\n",
      "Epoch 4/5\n",
      "353s - loss: 0.7186 - acc: 0.6995 - val_loss: 0.9266 - val_acc: 0.6261\n",
      "Epoch 5/5\n",
      "352s - loss: 0.6864 - acc: 0.7116 - val_loss: 0.9274 - val_acc: 0.6268\n",
      "Test accuracy: 0.626778162138\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "235s - loss: 0.9699 - acc: 0.5997 - val_loss: 0.9419 - val_acc: 0.6035\n",
      "Epoch 2/5\n",
      "234s - loss: 0.8368 - acc: 0.6529 - val_loss: 0.9052 - val_acc: 0.6229\n",
      "Epoch 3/5\n",
      "234s - loss: 0.7800 - acc: 0.6782 - val_loss: 0.9346 - val_acc: 0.6162\n",
      "Epoch 4/5\n",
      "233s - loss: 0.7421 - acc: 0.6943 - val_loss: 0.9665 - val_acc: 0.6084\n",
      "Epoch 5/5\n",
      "234s - loss: 0.7129 - acc: 0.7067 - val_loss: 0.9472 - val_acc: 0.6077\n",
      "Test accuracy: 0.622933487181\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "236s - loss: 0.9970 - acc: 0.5911 - val_loss: 0.9362 - val_acc: 0.6101\n",
      "Epoch 2/5\n",
      "234s - loss: 0.8328 - acc: 0.6553 - val_loss: 0.9148 - val_acc: 0.6210\n",
      "Epoch 3/5\n",
      "234s - loss: 0.7704 - acc: 0.6787 - val_loss: 0.9137 - val_acc: 0.6211\n",
      "Epoch 4/5\n",
      "234s - loss: 0.7300 - acc: 0.6959 - val_loss: 0.9197 - val_acc: 0.6248\n",
      "Epoch 5/5\n",
      "234s - loss: 0.6995 - acc: 0.7060 - val_loss: 0.9354 - val_acc: 0.6222\n",
      "Test accuracy: 0.624759707942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "185s - loss: 1.0427 - acc: 0.5773 - val_loss: 0.9481 - val_acc: 0.6031\n",
      "Epoch 2/5\n",
      "183s - loss: 0.8958 - acc: 0.6303 - val_loss: 0.9206 - val_acc: 0.6162\n",
      "Epoch 3/5\n",
      "183s - loss: 0.8419 - acc: 0.6528 - val_loss: 0.9197 - val_acc: 0.6140\n",
      "Epoch 4/5\n",
      "183s - loss: 0.8083 - acc: 0.6678 - val_loss: 0.9129 - val_acc: 0.6221\n",
      "Epoch 5/5\n",
      "183s - loss: 0.7831 - acc: 0.6801 - val_loss: 0.9357 - val_acc: 0.6142\n",
      "Test accuracy: 0.622132513449\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "174s - loss: 1.0085 - acc: 0.5893 - val_loss: 0.9284 - val_acc: 0.6118\n",
      "Epoch 2/5\n",
      "172s - loss: 0.8322 - acc: 0.6534 - val_loss: 0.9182 - val_acc: 0.6195\n",
      "Epoch 3/5\n",
      "172s - loss: 0.7745 - acc: 0.6768 - val_loss: 0.9191 - val_acc: 0.6185\n",
      "Epoch 4/5\n",
      "172s - loss: 0.7368 - acc: 0.6901 - val_loss: 0.9276 - val_acc: 0.6187\n",
      "Epoch 5/5\n",
      "172s - loss: 0.7087 - acc: 0.7018 - val_loss: 0.9434 - val_acc: 0.6109\n",
      "Test accuracy: 0.619505318605\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "236s - loss: 1.0022 - acc: 0.5876 - val_loss: 0.9419 - val_acc: 0.6058\n",
      "Epoch 2/5\n",
      "234s - loss: 0.8726 - acc: 0.6376 - val_loss: 0.9240 - val_acc: 0.6151\n",
      "Epoch 3/5\n",
      "234s - loss: 0.8202 - acc: 0.6614 - val_loss: 0.9248 - val_acc: 0.6158\n",
      "Epoch 4/5\n",
      "234s - loss: 0.7865 - acc: 0.6764 - val_loss: 0.9494 - val_acc: 0.6174\n",
      "Epoch 5/5\n",
      "234s - loss: 0.7625 - acc: 0.6878 - val_loss: 0.9163 - val_acc: 0.6280\n",
      "Test accuracy: 0.62802768176\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "236s - loss: 1.0096 - acc: 0.5844 - val_loss: 0.9476 - val_acc: 0.5999\n",
      "Epoch 2/5\n",
      "234s - loss: 0.8770 - acc: 0.6364 - val_loss: 0.9274 - val_acc: 0.6134\n",
      "Epoch 3/5\n",
      "234s - loss: 0.8237 - acc: 0.6607 - val_loss: 0.9269 - val_acc: 0.6118\n",
      "Epoch 4/5\n",
      "234s - loss: 0.7914 - acc: 0.6755 - val_loss: 0.9282 - val_acc: 0.6175\n",
      "Epoch 5/5\n",
      "234s - loss: 0.7675 - acc: 0.6850 - val_loss: 0.9297 - val_acc: 0.6138\n",
      "Test accuracy: 0.617518902925\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "188s - loss: 1.0081 - acc: 0.5852 - val_loss: 0.9583 - val_acc: 0.5964\n",
      "Epoch 2/5\n",
      "186s - loss: 0.8776 - acc: 0.6359 - val_loss: 0.9388 - val_acc: 0.6037\n",
      "Epoch 3/5\n",
      "185s - loss: 0.8261 - acc: 0.6589 - val_loss: 0.9177 - val_acc: 0.6208\n",
      "Epoch 4/5\n",
      "185s - loss: 0.7944 - acc: 0.6726 - val_loss: 0.9284 - val_acc: 0.6184\n",
      "Epoch 5/5\n",
      "185s - loss: 0.7723 - acc: 0.6826 - val_loss: 0.9125 - val_acc: 0.6219\n",
      "Test accuracy: 0.621908240359\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "364s - loss: 0.9873 - acc: 0.5943 - val_loss: 0.9361 - val_acc: 0.6040\n",
      "Epoch 2/5\n",
      "361s - loss: 0.8459 - acc: 0.6494 - val_loss: 0.9179 - val_acc: 0.6215\n",
      "Epoch 3/5\n",
      "362s - loss: 0.7878 - acc: 0.6756 - val_loss: 0.9153 - val_acc: 0.6289\n",
      "Epoch 4/5\n",
      "361s - loss: 0.7482 - acc: 0.6927 - val_loss: 0.9060 - val_acc: 0.6256\n",
      "Epoch 5/5\n",
      "369s - loss: 0.7179 - acc: 0.7064 - val_loss: 0.9515 - val_acc: 0.6169\n",
      "Test accuracy: 0.628892733579\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "191s - loss: 0.9429 - acc: 0.6113 - val_loss: 0.9297 - val_acc: 0.6145\n",
      "Epoch 2/5\n",
      "187s - loss: 0.7847 - acc: 0.6724 - val_loss: 0.9201 - val_acc: 0.6211\n",
      "Epoch 3/5\n",
      "187s - loss: 0.7238 - acc: 0.6968 - val_loss: 0.9356 - val_acc: 0.6192\n",
      "Epoch 4/5\n",
      "187s - loss: 0.6829 - acc: 0.7122 - val_loss: 0.9549 - val_acc: 0.6168\n",
      "Epoch 5/5\n",
      "187s - loss: 0.6498 - acc: 0.7232 - val_loss: 0.9531 - val_acc: 0.6163\n",
      "Test accuracy: 0.621139305372\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "239s - loss: 1.0017 - acc: 0.5883 - val_loss: 0.9527 - val_acc: 0.6061\n",
      "Epoch 2/5\n",
      "237s - loss: 0.8665 - acc: 0.6423 - val_loss: 0.9307 - val_acc: 0.6127\n",
      "Epoch 3/5\n",
      "236s - loss: 0.8135 - acc: 0.6643 - val_loss: 0.9116 - val_acc: 0.6242\n",
      "Epoch 4/5\n",
      "236s - loss: 0.7785 - acc: 0.6804 - val_loss: 0.9407 - val_acc: 0.6167\n",
      "Epoch 5/5\n",
      "236s - loss: 0.7538 - acc: 0.6902 - val_loss: 0.9471 - val_acc: 0.6057\n",
      "Test accuracy: 0.624183006505\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "375s - loss: 0.9734 - acc: 0.5991 - val_loss: 0.9159 - val_acc: 0.6184\n",
      "Epoch 2/5\n",
      "372s - loss: 0.8156 - acc: 0.6601 - val_loss: 0.9050 - val_acc: 0.6229\n",
      "Epoch 3/5\n",
      "372s - loss: 0.7543 - acc: 0.6843 - val_loss: 0.9101 - val_acc: 0.6288\n",
      "Epoch 4/5\n",
      "372s - loss: 0.7117 - acc: 0.7015 - val_loss: 0.9175 - val_acc: 0.6262\n",
      "Epoch 5/5\n",
      "372s - loss: 0.6806 - acc: 0.7123 - val_loss: 0.9245 - val_acc: 0.6230\n",
      "Test accuracy: 0.628764577658\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "174s - loss: 0.9607 - acc: 0.6062 - val_loss: 0.9271 - val_acc: 0.6138\n",
      "Epoch 2/5\n",
      "171s - loss: 0.7922 - acc: 0.6695 - val_loss: 0.9263 - val_acc: 0.6146\n",
      "Epoch 3/5\n",
      "171s - loss: 0.7328 - acc: 0.6941 - val_loss: 0.9379 - val_acc: 0.6145\n",
      "Epoch 4/5\n",
      "171s - loss: 0.6955 - acc: 0.7087 - val_loss: 0.9407 - val_acc: 0.6165\n",
      "Epoch 5/5\n",
      "170s - loss: 0.6646 - acc: 0.7200 - val_loss: 0.9487 - val_acc: 0.6143\n",
      "Test accuracy: 0.616461617296\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "172s - loss: 1.0100 - acc: 0.5863 - val_loss: 0.9460 - val_acc: 0.6019\n",
      "Epoch 2/5\n",
      "169s - loss: 0.8614 - acc: 0.6419 - val_loss: 0.9202 - val_acc: 0.6165\n",
      "Epoch 3/5\n",
      "169s - loss: 0.8081 - acc: 0.6667 - val_loss: 0.9320 - val_acc: 0.6110\n",
      "Epoch 4/5\n",
      "169s - loss: 0.7740 - acc: 0.6821 - val_loss: 0.9259 - val_acc: 0.6160\n",
      "Epoch 5/5\n",
      "169s - loss: 0.7490 - acc: 0.6930 - val_loss: 0.9395 - val_acc: 0.6122\n",
      "Test accuracy: 0.616525695429\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "379s - loss: 0.9704 - acc: 0.6038 - val_loss: 0.9220 - val_acc: 0.6135\n",
      "Epoch 2/5\n",
      "376s - loss: 0.8052 - acc: 0.6650 - val_loss: 0.9164 - val_acc: 0.6205\n",
      "Epoch 3/5\n",
      "398s - loss: 0.7401 - acc: 0.6903 - val_loss: 0.9178 - val_acc: 0.6237\n",
      "Epoch 4/5\n",
      "488s - loss: 0.6955 - acc: 0.7078 - val_loss: 0.9450 - val_acc: 0.6234\n",
      "Epoch 5/5\n",
      "486s - loss: 0.6582 - acc: 0.7219 - val_loss: 0.9704 - val_acc: 0.6139\n",
      "Test accuracy: 0.623734461166\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "483s - loss: 0.9786 - acc: 0.5994 - val_loss: 0.9444 - val_acc: 0.6068\n",
      "Epoch 2/5\n",
      "480s - loss: 0.8111 - acc: 0.6652 - val_loss: 0.9216 - val_acc: 0.6177\n",
      "Epoch 3/5\n",
      "478s - loss: 0.7451 - acc: 0.6880 - val_loss: 0.9214 - val_acc: 0.6188\n",
      "Epoch 4/5\n",
      "477s - loss: 0.7018 - acc: 0.7057 - val_loss: 0.9424 - val_acc: 0.6209\n",
      "Epoch 5/5\n",
      "476s - loss: 0.6655 - acc: 0.7202 - val_loss: 0.9635 - val_acc: 0.6128\n",
      "Test accuracy: 0.620882993904\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "478s - loss: 1.0049 - acc: 0.5904 - val_loss: 0.9364 - val_acc: 0.6088\n",
      "Epoch 2/5\n",
      "471s - loss: 0.8568 - acc: 0.6471 - val_loss: 0.9264 - val_acc: 0.6151\n",
      "Epoch 3/5\n",
      "471s - loss: 0.8013 - acc: 0.6711 - val_loss: 0.9217 - val_acc: 0.6224\n",
      "Epoch 4/5\n",
      "472s - loss: 0.7624 - acc: 0.6885 - val_loss: 0.9390 - val_acc: 0.6246\n",
      "Epoch 5/5\n",
      "472s - loss: 0.7326 - acc: 0.7002 - val_loss: 0.9360 - val_acc: 0.6240\n",
      "Test accuracy: 0.624599513061\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "484s - loss: 1.0039 - acc: 0.5906 - val_loss: 0.9482 - val_acc: 0.6087\n",
      "Epoch 2/5\n",
      "481s - loss: 0.8346 - acc: 0.6552 - val_loss: 0.9090 - val_acc: 0.6212\n",
      "Epoch 3/5\n",
      "481s - loss: 0.7711 - acc: 0.6779 - val_loss: 0.9319 - val_acc: 0.6223\n",
      "Epoch 4/5\n",
      "486s - loss: 0.7279 - acc: 0.6966 - val_loss: 0.9213 - val_acc: 0.6237\n",
      "Epoch 5/5\n",
      "483s - loss: 0.6957 - acc: 0.7075 - val_loss: 0.9300 - val_acc: 0.6217\n",
      "Test accuracy: 0.623670383232\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "485s - loss: 0.9434 - acc: 0.6103 - val_loss: 0.9163 - val_acc: 0.6173\n",
      "Epoch 2/5\n",
      "483s - loss: 0.7865 - acc: 0.6718 - val_loss: 0.9153 - val_acc: 0.6192\n",
      "Epoch 3/5\n",
      "479s - loss: 0.7214 - acc: 0.6976 - val_loss: 0.9310 - val_acc: 0.6225\n",
      "Epoch 4/5\n",
      "479s - loss: 0.6756 - acc: 0.7152 - val_loss: 0.9520 - val_acc: 0.6151\n",
      "Epoch 5/5\n",
      "482s - loss: 0.6401 - acc: 0.7289 - val_loss: 0.9565 - val_acc: 0.6207\n",
      "Test accuracy: 0.622516980626\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "485s - loss: 1.0122 - acc: 0.5856 - val_loss: 0.9610 - val_acc: 0.6016\n",
      "Epoch 2/5\n",
      "480s - loss: 0.8747 - acc: 0.6377 - val_loss: 0.9184 - val_acc: 0.6236\n",
      "Epoch 3/5\n",
      "480s - loss: 0.8222 - acc: 0.6609 - val_loss: 0.9062 - val_acc: 0.6243\n",
      "Epoch 4/5\n",
      "478s - loss: 0.7873 - acc: 0.6764 - val_loss: 0.9071 - val_acc: 0.6245\n",
      "Epoch 5/5\n",
      "480s - loss: 0.7612 - acc: 0.6884 - val_loss: 0.9165 - val_acc: 0.6280\n",
      "Test accuracy: 0.627963603727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "485s - loss: 0.9563 - acc: 0.6073 - val_loss: 0.9244 - val_acc: 0.6139\n",
      "Epoch 2/5\n",
      "486s - loss: 0.7920 - acc: 0.6705 - val_loss: 0.9189 - val_acc: 0.6198\n",
      "Epoch 3/5\n",
      "488s - loss: 0.7288 - acc: 0.6956 - val_loss: 0.9291 - val_acc: 0.6149\n",
      "Epoch 4/5\n",
      "485s - loss: 0.6860 - acc: 0.7114 - val_loss: 0.9469 - val_acc: 0.6195\n",
      "Epoch 5/5\n",
      "481s - loss: 0.6504 - acc: 0.7259 - val_loss: 0.9593 - val_acc: 0.6213\n",
      "Test accuracy: 0.621299500208\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "503s - loss: 1.0033 - acc: 0.5871 - val_loss: 1.0175 - val_acc: 0.5771\n",
      "Epoch 2/5\n",
      "498s - loss: 0.8722 - acc: 0.6396 - val_loss: 0.9182 - val_acc: 0.6167\n",
      "Epoch 3/5\n",
      "498s - loss: 0.8161 - acc: 0.6634 - val_loss: 0.9208 - val_acc: 0.6188\n",
      "Epoch 4/5\n",
      "498s - loss: 0.7806 - acc: 0.6792 - val_loss: 0.9425 - val_acc: 0.6131\n",
      "Epoch 5/5\n",
      "497s - loss: 0.7569 - acc: 0.6897 - val_loss: 0.9112 - val_acc: 0.6275\n",
      "Test accuracy: 0.627547097163\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "218s - loss: 0.9593 - acc: 0.6050 - val_loss: 0.9272 - val_acc: 0.6141\n",
      "Epoch 2/5\n",
      "215s - loss: 0.7905 - acc: 0.6702 - val_loss: 0.9262 - val_acc: 0.6173\n",
      "Epoch 3/5\n",
      "216s - loss: 0.7303 - acc: 0.6942 - val_loss: 0.9442 - val_acc: 0.6125\n",
      "Epoch 4/5\n",
      "215s - loss: 0.6916 - acc: 0.7097 - val_loss: 0.9466 - val_acc: 0.6199\n",
      "Epoch 5/5\n",
      "210s - loss: 0.6597 - acc: 0.7214 - val_loss: 0.9575 - val_acc: 0.6201\n",
      "Test accuracy: 0.620114058588\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "521s - loss: 1.0092 - acc: 0.5850 - val_loss: 0.9397 - val_acc: 0.6078\n",
      "Epoch 2/5\n",
      "512s - loss: 0.8764 - acc: 0.6359 - val_loss: 0.9369 - val_acc: 0.6099\n",
      "Epoch 3/5\n",
      "510s - loss: 0.8233 - acc: 0.6615 - val_loss: 0.9265 - val_acc: 0.6174\n",
      "Epoch 4/5\n",
      "511s - loss: 0.7887 - acc: 0.6765 - val_loss: 0.9092 - val_acc: 0.6226\n",
      "Epoch 5/5\n",
      "510s - loss: 0.7643 - acc: 0.6883 - val_loss: 0.9323 - val_acc: 0.6104\n",
      "Test accuracy: 0.622645136417\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "521s - loss: 0.9531 - acc: 0.6089 - val_loss: 0.9241 - val_acc: 0.6163\n",
      "Epoch 2/5\n",
      "510s - loss: 0.7910 - acc: 0.6712 - val_loss: 0.9173 - val_acc: 0.6220\n",
      "Epoch 3/5\n",
      "514s - loss: 0.7257 - acc: 0.6972 - val_loss: 0.9251 - val_acc: 0.6162\n",
      "Epoch 4/5\n",
      "513s - loss: 0.6808 - acc: 0.7145 - val_loss: 0.9488 - val_acc: 0.6130\n",
      "Epoch 5/5\n",
      "511s - loss: 0.6422 - acc: 0.7287 - val_loss: 0.9650 - val_acc: 0.6201\n",
      "Test accuracy: 0.622036396235\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "264s - loss: 1.0471 - acc: 0.5735 - val_loss: 0.9525 - val_acc: 0.6027\n",
      "Epoch 2/5\n",
      "255s - loss: 0.8971 - acc: 0.6292 - val_loss: 0.9242 - val_acc: 0.6127\n",
      "Epoch 3/5\n",
      "255s - loss: 0.8435 - acc: 0.6536 - val_loss: 0.9114 - val_acc: 0.6206\n",
      "Epoch 4/5\n",
      "257s - loss: 0.8107 - acc: 0.6668 - val_loss: 0.9142 - val_acc: 0.6176\n",
      "Epoch 5/5\n",
      "262s - loss: 0.7848 - acc: 0.6799 - val_loss: 0.9285 - val_acc: 0.6149\n",
      "Test accuracy: 0.620594643025\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "545s - loss: 0.9732 - acc: 0.5971 - val_loss: 0.9381 - val_acc: 0.6084\n",
      "Epoch 2/5\n",
      "523s - loss: 0.8382 - acc: 0.6516 - val_loss: 0.9270 - val_acc: 0.6139\n",
      "Epoch 3/5\n",
      "525s - loss: 0.7811 - acc: 0.6774 - val_loss: 0.9172 - val_acc: 0.6201\n",
      "Epoch 4/5\n",
      "525s - loss: 0.7429 - acc: 0.6941 - val_loss: 0.9188 - val_acc: 0.6249\n",
      "Epoch 5/5\n",
      "522s - loss: 0.7145 - acc: 0.7076 - val_loss: 0.9495 - val_acc: 0.6114\n",
      "Test accuracy: 0.624919902663\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "541s - loss: 0.9520 - acc: 0.6075 - val_loss: 0.9189 - val_acc: 0.6142\n",
      "Epoch 2/5\n",
      "536s - loss: 0.7917 - acc: 0.6688 - val_loss: 0.9214 - val_acc: 0.6228\n",
      "Epoch 3/5\n",
      "535s - loss: 0.7281 - acc: 0.6944 - val_loss: 0.9238 - val_acc: 0.6183\n",
      "Epoch 4/5\n",
      "537s - loss: 0.6855 - acc: 0.7116 - val_loss: 0.9441 - val_acc: 0.6191\n",
      "Test accuracy: 0.622805331344\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "220s - loss: 1.0323 - acc: 0.5803 - val_loss: 0.9549 - val_acc: 0.6007\n",
      "Epoch 2/5\n",
      "214s - loss: 0.8901 - acc: 0.6313 - val_loss: 0.9243 - val_acc: 0.6137\n",
      "Epoch 3/5\n",
      "217s - loss: 0.8365 - acc: 0.6545 - val_loss: 0.9129 - val_acc: 0.6174\n",
      "Epoch 4/5\n",
      "214s - loss: 0.8002 - acc: 0.6718 - val_loss: 0.9116 - val_acc: 0.6229\n",
      "Epoch 5/5\n",
      "216s - loss: 0.7756 - acc: 0.6817 - val_loss: 0.9335 - val_acc: 0.6132\n",
      "Test accuracy: 0.622933487349\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "541s - loss: 0.9446 - acc: 0.6091 - val_loss: 0.9189 - val_acc: 0.6177\n",
      "Epoch 2/5\n",
      "532s - loss: 0.7884 - acc: 0.6701 - val_loss: 0.9171 - val_acc: 0.6187\n",
      "Epoch 3/5\n",
      "534s - loss: 0.7250 - acc: 0.6955 - val_loss: 0.9385 - val_acc: 0.6236\n",
      "Epoch 4/5\n",
      "534s - loss: 0.6816 - acc: 0.7129 - val_loss: 0.9361 - val_acc: 0.6244\n",
      "Epoch 5/5\n",
      "530s - loss: 0.6477 - acc: 0.7254 - val_loss: 0.9593 - val_acc: 0.6167\n",
      "Test accuracy: 0.624375240307\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "275s - loss: 1.0293 - acc: 0.5789 - val_loss: 0.9564 - val_acc: 0.5996\n",
      "Epoch 2/5\n",
      "267s - loss: 0.8837 - acc: 0.6341 - val_loss: 0.9235 - val_acc: 0.6142\n",
      "Epoch 3/5\n",
      "269s - loss: 0.8278 - acc: 0.6583 - val_loss: 0.9265 - val_acc: 0.6106\n",
      "Epoch 4/5\n",
      "269s - loss: 0.7941 - acc: 0.6727 - val_loss: 0.9104 - val_acc: 0.6209\n",
      "Epoch 5/5\n",
      "268s - loss: 0.7672 - acc: 0.6851 - val_loss: 0.9064 - val_acc: 0.6258\n",
      "Test accuracy: 0.62575291553\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "562s - loss: 0.9460 - acc: 0.6102 - val_loss: 0.9238 - val_acc: 0.6117\n",
      "Epoch 2/5\n",
      "551s - loss: 0.7862 - acc: 0.6713 - val_loss: 0.9229 - val_acc: 0.6212\n",
      "Epoch 3/5\n",
      "546s - loss: 0.7233 - acc: 0.6978 - val_loss: 0.9444 - val_acc: 0.6237\n",
      "Epoch 4/5\n",
      "550s - loss: 0.6807 - acc: 0.7127 - val_loss: 0.9580 - val_acc: 0.6163\n",
      "Epoch 5/5\n",
      "549s - loss: 0.6444 - acc: 0.7266 - val_loss: 0.9721 - val_acc: 0.6232\n",
      "Test accuracy: 0.623670383079\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "576s - loss: 1.0056 - acc: 0.5851 - val_loss: 0.9416 - val_acc: 0.6033\n",
      "Epoch 2/5\n",
      "578s - loss: 0.8708 - acc: 0.6387 - val_loss: 0.9256 - val_acc: 0.6134\n",
      "Epoch 3/5\n",
      "572s - loss: 0.8176 - acc: 0.6635 - val_loss: 0.9126 - val_acc: 0.6242\n",
      "Epoch 4/5\n",
      "574s - loss: 0.7823 - acc: 0.6786 - val_loss: 0.9302 - val_acc: 0.6194\n",
      "Epoch 5/5\n",
      "574s - loss: 0.7568 - acc: 0.6910 - val_loss: 0.9094 - val_acc: 0.6259\n",
      "Test accuracy: 0.625913110396\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "576s - loss: 0.9451 - acc: 0.6092 - val_loss: 0.9187 - val_acc: 0.6182\n",
      "Epoch 2/5\n",
      "575s - loss: 0.7836 - acc: 0.6740 - val_loss: 0.9184 - val_acc: 0.6227\n",
      "Epoch 3/5\n",
      "577s - loss: 0.7211 - acc: 0.6979 - val_loss: 0.9149 - val_acc: 0.6226\n",
      "Epoch 4/5\n",
      "570s - loss: 0.6769 - acc: 0.7160 - val_loss: 0.9272 - val_acc: 0.6225\n",
      "Epoch 5/5\n",
      "571s - loss: 0.6394 - acc: 0.7292 - val_loss: 0.9579 - val_acc: 0.6202\n",
      "Test accuracy: 0.622677175545\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "496s - loss: 0.9923 - acc: 0.5937 - val_loss: 0.9235 - val_acc: 0.6132\n",
      "Epoch 2/5\n",
      "489s - loss: 0.8256 - acc: 0.6573 - val_loss: 0.9294 - val_acc: 0.6155\n",
      "Epoch 3/5\n",
      "504s - loss: 0.7656 - acc: 0.6811 - val_loss: 0.9185 - val_acc: 0.6236\n",
      "Epoch 4/5\n",
      "494s - loss: 0.7268 - acc: 0.6952 - val_loss: 0.9346 - val_acc: 0.6229\n",
      "Epoch 5/5\n",
      "491s - loss: 0.6948 - acc: 0.7080 - val_loss: 0.9394 - val_acc: 0.6235\n",
      "Test accuracy: 0.623574266323\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "222s - loss: 1.0469 - acc: 0.5740 - val_loss: 0.9566 - val_acc: 0.6009\n",
      "Epoch 2/5\n",
      "208s - loss: 0.8953 - acc: 0.6293 - val_loss: 0.9209 - val_acc: 0.6167\n",
      "Epoch 3/5\n",
      "206s - loss: 0.8437 - acc: 0.6514 - val_loss: 0.9200 - val_acc: 0.6172\n",
      "Epoch 4/5\n",
      "199s - loss: 0.8095 - acc: 0.6666 - val_loss: 0.9238 - val_acc: 0.6113\n",
      "Epoch 5/5\n",
      "202s - loss: 0.7860 - acc: 0.6776 - val_loss: 0.9170 - val_acc: 0.6188\n",
      "Test accuracy: 0.61883250042\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "271s - loss: 0.9803 - acc: 0.5965 - val_loss: 0.9706 - val_acc: 0.5950\n",
      "Epoch 2/5\n",
      "248s - loss: 0.8491 - acc: 0.6478 - val_loss: 0.9219 - val_acc: 0.6159\n",
      "Epoch 3/5\n",
      "248s - loss: 0.7941 - acc: 0.6716 - val_loss: 0.9244 - val_acc: 0.6178\n",
      "Epoch 4/5\n",
      "244s - loss: 0.7608 - acc: 0.6859 - val_loss: 0.9453 - val_acc: 0.6183\n",
      "Epoch 5/5\n",
      "272s - loss: 0.7348 - acc: 0.6977 - val_loss: 0.9264 - val_acc: 0.6211\n",
      "Test accuracy: 0.6210752275\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663s - loss: 0.9828 - acc: 0.5972 - val_loss: 0.9248 - val_acc: 0.6130\n",
      "Epoch 2/5\n",
      "623s - loss: 0.8222 - acc: 0.6588 - val_loss: 0.9127 - val_acc: 0.6250\n",
      "Epoch 3/5\n",
      "630s - loss: 0.7592 - acc: 0.6835 - val_loss: 0.9229 - val_acc: 0.6239\n",
      "Epoch 4/5\n",
      "617s - loss: 0.7156 - acc: 0.6999 - val_loss: 0.9184 - val_acc: 0.6246\n",
      "Epoch 5/5\n",
      "624s - loss: 0.6830 - acc: 0.7107 - val_loss: 0.9365 - val_acc: 0.6184\n",
      "Test accuracy: 0.625048058577\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "529s - loss: 1.0268 - acc: 0.5809 - val_loss: 0.9620 - val_acc: 0.5987\n",
      "Epoch 2/5\n",
      "521s - loss: 0.8845 - acc: 0.6330 - val_loss: 0.9169 - val_acc: 0.6184\n",
      "Epoch 3/5\n",
      "518s - loss: 0.8301 - acc: 0.6588 - val_loss: 0.9385 - val_acc: 0.6048\n",
      "Epoch 4/5\n",
      "522s - loss: 0.7955 - acc: 0.6734 - val_loss: 0.9036 - val_acc: 0.6261\n",
      "Epoch 5/5\n",
      "522s - loss: 0.7711 - acc: 0.6843 - val_loss: 0.9180 - val_acc: 0.6171\n",
      "Test accuracy: 0.626137382997\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "274s - loss: 0.9456 - acc: 0.6113 - val_loss: 0.9263 - val_acc: 0.6134\n",
      "Epoch 2/5\n",
      "271s - loss: 0.7841 - acc: 0.6733 - val_loss: 0.9174 - val_acc: 0.6221\n",
      "Epoch 3/5\n",
      "278s - loss: 0.7223 - acc: 0.6972 - val_loss: 0.9273 - val_acc: 0.6236\n",
      "Epoch 4/5\n",
      "274s - loss: 0.6811 - acc: 0.7135 - val_loss: 0.9474 - val_acc: 0.6191\n",
      "Epoch 5/5\n",
      "280s - loss: 0.6494 - acc: 0.7245 - val_loss: 0.9699 - val_acc: 0.6185\n",
      "Test accuracy: 0.623638344196\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "743s - loss: 1.0049 - acc: 0.5855 - val_loss: 0.9534 - val_acc: 0.5991\n",
      "Epoch 2/5\n",
      "619s - loss: 0.8678 - acc: 0.6400 - val_loss: 0.9107 - val_acc: 0.6203\n",
      "Epoch 3/5\n",
      "597s - loss: 0.8134 - acc: 0.6646 - val_loss: 0.9336 - val_acc: 0.6151\n",
      "Epoch 4/5\n",
      "590s - loss: 0.7788 - acc: 0.6812 - val_loss: 0.9169 - val_acc: 0.6241\n",
      "Epoch 5/5\n",
      "582s - loss: 0.7511 - acc: 0.6925 - val_loss: 0.9288 - val_acc: 0.6250\n",
      "Test accuracy: 0.624951941584\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "462s - loss: 0.9806 - acc: 0.6019 - val_loss: 0.9249 - val_acc: 0.6137\n",
      "Epoch 2/5\n",
      "460s - loss: 0.8092 - acc: 0.6638 - val_loss: 0.9259 - val_acc: 0.6204\n",
      "Epoch 3/5\n",
      "459s - loss: 0.7445 - acc: 0.6891 - val_loss: 0.9359 - val_acc: 0.6191\n",
      "Epoch 4/5\n",
      "460s - loss: 0.7017 - acc: 0.7063 - val_loss: 0.9486 - val_acc: 0.6231\n",
      "Test accuracy: 0.623061643095\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "659s - loss: 0.9996 - acc: 0.5877 - val_loss: 0.9456 - val_acc: 0.6033\n",
      "Epoch 2/5\n",
      "1122s - loss: 0.8682 - acc: 0.6407 - val_loss: 0.9305 - val_acc: 0.6111\n",
      "Epoch 3/5\n",
      "848s - loss: 0.8167 - acc: 0.6626 - val_loss: 0.9717 - val_acc: 0.5984\n",
      "Epoch 4/5\n",
      "797s - loss: 0.7813 - acc: 0.6787 - val_loss: 0.9566 - val_acc: 0.6119\n",
      "Epoch 5/5\n",
      "798s - loss: 0.7563 - acc: 0.6901 - val_loss: 0.9375 - val_acc: 0.6205\n",
      "Test accuracy: 0.62053056519\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "225s - loss: 0.9807 - acc: 0.6009 - val_loss: 0.9284 - val_acc: 0.6115\n",
      "Epoch 2/5\n",
      "220s - loss: 0.8058 - acc: 0.6646 - val_loss: 0.9311 - val_acc: 0.6143\n",
      "Epoch 3/5\n",
      "221s - loss: 0.7446 - acc: 0.6885 - val_loss: 0.9323 - val_acc: 0.6153\n",
      "Epoch 4/5\n",
      "220s - loss: 0.7058 - acc: 0.7040 - val_loss: 0.9424 - val_acc: 0.6157\n",
      "Test accuracy: 0.615692682355\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "325s - loss: 1.0294 - acc: 0.5796 - val_loss: 0.9473 - val_acc: 0.6055\n",
      "Epoch 2/5\n",
      "318s - loss: 0.8862 - acc: 0.6330 - val_loss: 0.9245 - val_acc: 0.6138\n",
      "Epoch 3/5\n",
      "317s - loss: 0.8321 - acc: 0.6547 - val_loss: 0.9140 - val_acc: 0.6176\n",
      "Epoch 4/5\n",
      "317s - loss: 0.7986 - acc: 0.6717 - val_loss: 0.9115 - val_acc: 0.6235\n",
      "Epoch 5/5\n",
      "321s - loss: 0.7730 - acc: 0.6827 - val_loss: 0.9122 - val_acc: 0.6252\n",
      "Test accuracy: 0.625240292218\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "626s - loss: 0.9453 - acc: 0.6103 - val_loss: 0.9302 - val_acc: 0.6103\n",
      "Epoch 2/5\n",
      "618s - loss: 0.7881 - acc: 0.6715 - val_loss: 0.9241 - val_acc: 0.6135\n",
      "Epoch 3/5\n",
      "621s - loss: 0.7230 - acc: 0.6955 - val_loss: 0.9339 - val_acc: 0.6142\n",
      "Epoch 4/5\n",
      "626s - loss: 0.6833 - acc: 0.7115 - val_loss: 0.9446 - val_acc: 0.6191\n",
      "Epoch 5/5\n",
      "633s - loss: 0.6472 - acc: 0.7250 - val_loss: 0.9736 - val_acc: 0.6091\n",
      "Test accuracy: 0.619088812087\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "870s - loss: 1.0133 - acc: 0.5845 - val_loss: 0.9615 - val_acc: 0.5963\n",
      "Epoch 2/5\n",
      "860s - loss: 0.8735 - acc: 0.6389 - val_loss: 0.9128 - val_acc: 0.6183\n",
      "Epoch 3/5\n",
      "861s - loss: 0.8191 - acc: 0.6622 - val_loss: 0.9121 - val_acc: 0.6258\n",
      "Epoch 4/5\n",
      "861s - loss: 0.7839 - acc: 0.6780 - val_loss: 0.9004 - val_acc: 0.6287\n",
      "Epoch 5/5\n",
      "862s - loss: 0.7568 - acc: 0.6914 - val_loss: 0.9333 - val_acc: 0.6230\n",
      "Test accuracy: 0.628732538706\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "373s - loss: 0.9579 - acc: 0.6051 - val_loss: 0.9267 - val_acc: 0.6149\n",
      "Epoch 2/5\n",
      "363s - loss: 0.7931 - acc: 0.6688 - val_loss: 0.9305 - val_acc: 0.6184\n",
      "Epoch 3/5\n",
      "366s - loss: 0.7342 - acc: 0.6931 - val_loss: 0.9496 - val_acc: 0.6105\n",
      "Epoch 4/5\n",
      "360s - loss: 0.6943 - acc: 0.7088 - val_loss: 0.9460 - val_acc: 0.6164\n",
      "Test accuracy: 0.618383954988\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "850s - loss: 1.0030 - acc: 0.5876 - val_loss: 0.9397 - val_acc: 0.6051\n",
      "Epoch 2/5\n",
      "847s - loss: 0.8682 - acc: 0.6415 - val_loss: 0.9262 - val_acc: 0.6141\n",
      "Epoch 3/5\n",
      "849s - loss: 0.8150 - acc: 0.6632 - val_loss: 0.9226 - val_acc: 0.6175\n",
      "Epoch 4/5\n",
      "849s - loss: 0.7792 - acc: 0.6803 - val_loss: 0.9403 - val_acc: 0.6094\n",
      "Epoch 5/5\n",
      "849s - loss: 0.7520 - acc: 0.6915 - val_loss: 0.9455 - val_acc: 0.6153\n",
      "Test accuracy: 0.617454825083\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "855s - loss: 0.9764 - acc: 0.6020 - val_loss: 0.9246 - val_acc: 0.6161\n",
      "Epoch 2/5\n",
      "850s - loss: 0.8044 - acc: 0.6661 - val_loss: 0.9133 - val_acc: 0.6214\n",
      "Epoch 3/5\n",
      "847s - loss: 0.7395 - acc: 0.6915 - val_loss: 0.9334 - val_acc: 0.6247\n",
      "Epoch 4/5\n",
      "851s - loss: 0.6950 - acc: 0.7080 - val_loss: 0.9450 - val_acc: 0.6251\n",
      "Epoch 5/5\n",
      "847s - loss: 0.6583 - acc: 0.7220 - val_loss: 0.9671 - val_acc: 0.6176\n",
      "Test accuracy: 0.625112136541\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "647s - loss: 1.0025 - acc: 0.5888 - val_loss: 0.9390 - val_acc: 0.6018\n",
      "Epoch 2/5\n",
      "642s - loss: 0.8710 - acc: 0.6388 - val_loss: 0.9167 - val_acc: 0.6169\n",
      "Epoch 3/5\n",
      "645s - loss: 0.8179 - acc: 0.6611 - val_loss: 0.9118 - val_acc: 0.6169\n",
      "Epoch 4/5\n",
      "644s - loss: 0.7841 - acc: 0.6777 - val_loss: 0.9078 - val_acc: 0.6258\n",
      "Epoch 5/5\n",
      "644s - loss: 0.7602 - acc: 0.6869 - val_loss: 0.9191 - val_acc: 0.6210\n",
      "Test accuracy: 0.625784954612\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "911s - loss: 0.9571 - acc: 0.6076 - val_loss: 0.9198 - val_acc: 0.6159\n",
      "Epoch 2/5\n",
      "898s - loss: 0.7948 - acc: 0.6693 - val_loss: 0.9233 - val_acc: 0.6239\n",
      "Epoch 3/5\n",
      "900s - loss: 0.7314 - acc: 0.6950 - val_loss: 0.9192 - val_acc: 0.6249\n",
      "Epoch 4/5\n",
      "896s - loss: 0.6859 - acc: 0.7121 - val_loss: 0.9453 - val_acc: 0.6261\n",
      "Epoch 5/5\n",
      "895s - loss: 0.6497 - acc: 0.7263 - val_loss: 0.9457 - val_acc: 0.6209\n",
      "Test accuracy: 0.626073305231\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "438s - loss: 1.0395 - acc: 0.5767 - val_loss: 0.9490 - val_acc: 0.6061\n",
      "Epoch 2/5\n",
      "418s - loss: 0.8928 - acc: 0.6301 - val_loss: 0.9244 - val_acc: 0.6159\n",
      "Epoch 3/5\n",
      "415s - loss: 0.8375 - acc: 0.6550 - val_loss: 0.9099 - val_acc: 0.6204\n",
      "Epoch 4/5\n",
      "416s - loss: 0.8046 - acc: 0.6694 - val_loss: 0.9130 - val_acc: 0.6210\n",
      "Epoch 5/5\n",
      "415s - loss: 0.7785 - acc: 0.6817 - val_loss: 0.9144 - val_acc: 0.6222\n",
      "Test accuracy: 0.622196591154\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "428s - loss: 0.9536 - acc: 0.6077 - val_loss: 0.9378 - val_acc: 0.6129\n",
      "Epoch 2/5\n",
      "415s - loss: 0.7905 - acc: 0.6704 - val_loss: 0.9285 - val_acc: 0.6174\n",
      "Epoch 3/5\n",
      "411s - loss: 0.7310 - acc: 0.6928 - val_loss: 0.9357 - val_acc: 0.6141\n",
      "Epoch 4/5\n",
      "414s - loss: 0.6935 - acc: 0.7078 - val_loss: 0.9487 - val_acc: 0.6154\n",
      "Epoch 5/5\n",
      "403s - loss: 0.6628 - acc: 0.7211 - val_loss: 0.9635 - val_acc: 0.6142\n",
      "Test accuracy: 0.617358708044\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "903s - loss: 1.0088 - acc: 0.5873 - val_loss: 0.9477 - val_acc: 0.6033\n",
      "Epoch 2/5\n",
      "891s - loss: 0.8714 - acc: 0.6395 - val_loss: 0.9255 - val_acc: 0.6100\n",
      "Epoch 3/5\n",
      "893s - loss: 0.8169 - acc: 0.6627 - val_loss: 0.9134 - val_acc: 0.6265\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899s - loss: 0.7795 - acc: 0.6787 - val_loss: 0.9132 - val_acc: 0.6227\n",
      "Epoch 5/5\n",
      "901s - loss: 0.7542 - acc: 0.6916 - val_loss: 0.9103 - val_acc: 0.6262\n",
      "Test accuracy: 0.626457772789\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "977s - loss: 0.9587 - acc: 0.6065 - val_loss: 0.9202 - val_acc: 0.6129\n",
      "Epoch 2/5\n",
      "939s - loss: 0.7931 - acc: 0.6713 - val_loss: 0.9141 - val_acc: 0.6208\n",
      "Epoch 3/5\n",
      "929s - loss: 0.7293 - acc: 0.6937 - val_loss: 0.9309 - val_acc: 0.6202\n",
      "Epoch 4/5\n",
      "928s - loss: 0.6845 - acc: 0.7116 - val_loss: 0.9320 - val_acc: 0.6244\n",
      "Epoch 5/5\n",
      "926s - loss: 0.6494 - acc: 0.7246 - val_loss: 0.9593 - val_acc: 0.6170\n",
      "Test accuracy: 0.62440727919\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "940s - loss: 0.9729 - acc: 0.5993 - val_loss: 0.9412 - val_acc: 0.6082\n",
      "Epoch 2/5\n",
      "927s - loss: 0.8379 - acc: 0.6532 - val_loss: 0.9147 - val_acc: 0.6145\n",
      "Epoch 3/5\n",
      "928s - loss: 0.7793 - acc: 0.6778 - val_loss: 0.9078 - val_acc: 0.6268\n",
      "Epoch 4/5\n",
      "926s - loss: 0.7414 - acc: 0.6956 - val_loss: 0.9293 - val_acc: 0.6135\n",
      "Epoch 5/5\n",
      "924s - loss: 0.7140 - acc: 0.7075 - val_loss: 0.9466 - val_acc: 0.6238\n",
      "Test accuracy: 0.626810201182\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "731s - loss: 0.9936 - acc: 0.5940 - val_loss: 0.9258 - val_acc: 0.6156\n",
      "Epoch 2/5\n",
      "700s - loss: 0.8242 - acc: 0.6575 - val_loss: 0.9098 - val_acc: 0.6209\n",
      "Epoch 3/5\n",
      "701s - loss: 0.7620 - acc: 0.6825 - val_loss: 0.9240 - val_acc: 0.6239\n",
      "Epoch 4/5\n",
      "697s - loss: 0.7233 - acc: 0.6966 - val_loss: 0.9336 - val_acc: 0.6205\n",
      "Epoch 5/5\n",
      "698s - loss: 0.6929 - acc: 0.7073 - val_loss: 0.9399 - val_acc: 0.6198\n",
      "Test accuracy: 0.623894655795\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "969s - loss: 0.9840 - acc: 0.5955 - val_loss: 0.9366 - val_acc: 0.6061\n",
      "Epoch 2/5\n",
      "964s - loss: 0.8451 - acc: 0.6509 - val_loss: 0.9162 - val_acc: 0.6227\n",
      "Epoch 3/5\n",
      "964s - loss: 0.7855 - acc: 0.6776 - val_loss: 0.9355 - val_acc: 0.6177\n",
      "Epoch 4/5\n",
      "963s - loss: 0.7468 - acc: 0.6937 - val_loss: 0.9672 - val_acc: 0.6209\n",
      "Epoch 5/5\n",
      "964s - loss: 0.7152 - acc: 0.7063 - val_loss: 0.9459 - val_acc: 0.6247\n",
      "Test accuracy: 0.624727668906\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "987s - loss: 1.0193 - acc: 0.5823 - val_loss: 0.9541 - val_acc: 0.5967\n",
      "Epoch 2/5\n",
      "956s - loss: 0.8748 - acc: 0.6386 - val_loss: 0.9254 - val_acc: 0.6201\n",
      "Epoch 3/5\n",
      "972s - loss: 0.8199 - acc: 0.6623 - val_loss: 0.9178 - val_acc: 0.6212\n",
      "Epoch 4/5\n",
      "982s - loss: 0.7838 - acc: 0.6798 - val_loss: 0.9118 - val_acc: 0.6229\n",
      "Epoch 5/5\n",
      "964s - loss: 0.7549 - acc: 0.6905 - val_loss: 0.9038 - val_acc: 0.6293\n",
      "Test accuracy: 0.629277201015\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "959s - loss: 1.0227 - acc: 0.5831 - val_loss: 0.9737 - val_acc: 0.5919\n",
      "Epoch 2/5\n",
      "946s - loss: 0.8782 - acc: 0.6369 - val_loss: 0.9203 - val_acc: 0.6167\n",
      "Epoch 3/5\n",
      "950s - loss: 0.8203 - acc: 0.6627 - val_loss: 0.9046 - val_acc: 0.6268\n",
      "Epoch 4/5\n",
      "957s - loss: 0.7830 - acc: 0.6789 - val_loss: 0.9087 - val_acc: 0.6209\n",
      "Epoch 5/5\n",
      "1041s - loss: 0.7560 - acc: 0.6909 - val_loss: 0.9148 - val_acc: 0.6304\n",
      "Test accuracy: 0.630398564594\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n",
      "1316s - loss: 1.0126 - acc: 0.5844 - val_loss: 0.9331 - val_acc: 0.6085\n",
      "Epoch 2/5\n",
      "1353s - loss: 0.8744 - acc: 0.6384 - val_loss: 0.9205 - val_acc: 0.6167\n",
      "Epoch 3/5\n",
      "893s - loss: 0.8201 - acc: 0.6617 - val_loss: 0.9073 - val_acc: 0.6207\n",
      "Epoch 4/5\n",
      "865s - loss: 0.7829 - acc: 0.6792 - val_loss: 0.9087 - val_acc: 0.6282\n",
      "Epoch 5/5\n",
      "901s - loss: 0.7569 - acc: 0.6895 - val_loss: 0.9140 - val_acc: 0.6206\n",
      "Test accuracy: 0.628187876565\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[128,49,2048]\n\t [[Node: gradients_69/lstm_70/transpose_grad/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _class=[\"loc:@lstm_70/transpose\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_69/lstm_70/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3, gradients_69/lstm_70/transpose_grad/InvertPermutation)]]\n\nCaused by op 'gradients_69/lstm_70/transpose_grad/transpose', defined at:\n  File \"C:\\Python\\Python35\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Python\\Python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Python\\Python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-017579302fbf>\", line 3, in <module>\n    trials=Trials(),notebook_name='Best',rseed=1)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\", line 42, in minimize\n    notebook_name=notebook_name, verbose=verbose)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\", line 90, in base_minimizer\n    rstate=np.random.RandomState(rseed))\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\", line 307, in fmin\n    return_argmin=return_argmin,\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\base.py\", line 635, in fmin\n    return_argmin=return_argmin)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\", line 320, in fmin\n    rval.exhaust()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\", line 199, in exhaust\n    self.run(self.max_evals - n_done, block_until_done=self.async)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\", line 173, in run\n    self.serial_evaluate()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\", line 92, in serial_evaluate\n    result = self.domain.evaluate(spec, ctrl)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\base.py\", line 840, in evaluate\n    rval = self.fn(pyll_rval)\n  File \"C:\\Users\\Simas\\Desktop\\Kaggle\\Movie Sentiment\\temp_model.py\", line 131, in keras_fmin_fnct\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\models.py\", line 845, in fit\n    initial_epoch=initial_epoch)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\engine\\training.py\", line 1457, in fit\n    self._make_train_function()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\engine\\training.py\", line 1001, in _make_train_function\n    self.total_loss)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\optimizers.py\", line 197, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\optimizers.py\", line 47, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2108, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 560, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 368, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 560, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\", line 426, in _TransposeGrad\n    return [array_ops.transpose(grad, array_ops.invert_permutation(p)), None]\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1270, in transpose\n    ret = gen_array_ops.transpose(a, perm, name=name)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3721, in transpose\n    result = _op_def_lib.apply_op(\"Transpose\", x=x, perm=perm, name=name)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'lstm_70/transpose', defined at:\n  File \"C:\\Python\\Python35\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 28 identical lines from previous traceback]\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\base.py\", line 840, in evaluate\n    rval = self.fn(pyll_rval)\n  File \"C:\\Users\\Simas\\Desktop\\Kaggle\\Movie Sentiment\\temp_model.py\", line 119, in keras_fmin_fnct\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\models.py\", line 455, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 252, in __call__\n    return super(Recurrent, self).__call__(inputs, **kwargs)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\engine\\topology.py\", line 554, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 298, in call\n    input_length=input_shape[1])\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2178, in rnn\n    inputs = tf.transpose(inputs, (axes))\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1270, in transpose\n    ret = gen_array_ops.transpose(a, perm, name=name)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3721, in transpose\n    result = _op_def_lib.apply_op(\"Transpose\", x=x, perm=perm, name=name)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[128,49,2048]\n\t [[Node: gradients_69/lstm_70/transpose_grad/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _class=[\"loc:@lstm_70/transpose\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_69/lstm_70/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3, gradients_69/lstm_70/transpose_grad/InvertPermutation)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\u001b[0m\n\u001b[0;32m     82\u001b[0m                         \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                         rseed=rseed)\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fmin() got an unexpected keyword argument 'rseed'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,49,2048]\n\t [[Node: gradients_69/lstm_70/transpose_grad/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _class=[\"loc:@lstm_70/transpose\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_69/lstm_70/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3, gradients_69/lstm_70/transpose_grad/InvertPermutation)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-017579302fbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m best_run, best_model = optim.minimize(model=model, data=data, algo=tpe.suggest, max_evals = 100, \n\u001b[1;32m----> 3\u001b[1;33m                                       trials=Trials(),notebook_name='Best',rseed=1)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(model, data, algo, max_evals, trials, rseed, notebook_name, verbose)\u001b[0m\n\u001b[0;32m     40\u001b[0m     best_run = base_minimizer(model=model, data=data, algo=algo, max_evals=max_evals,\n\u001b[0;32m     41\u001b[0m                               \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_model_string\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                               notebook_name=notebook_name, verbose=verbose)\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\u001b[0m\n\u001b[0;32m     88\u001b[0m                         \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                         \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                         rstate=np.random.RandomState(rseed))\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_run\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         )\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    318\u001b[0m                     verbose=verbose)\n\u001b[0;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Simas\\Desktop\\Kaggle\\Movie Sentiment\\temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[1;34m(space)\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1485\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1140\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1141\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 2073\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   2074\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,49,2048]\n\t [[Node: gradients_69/lstm_70/transpose_grad/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _class=[\"loc:@lstm_70/transpose\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_69/lstm_70/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3, gradients_69/lstm_70/transpose_grad/InvertPermutation)]]\n\nCaused by op 'gradients_69/lstm_70/transpose_grad/transpose', defined at:\n  File \"C:\\Python\\Python35\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Python\\Python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Python\\Python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-017579302fbf>\", line 3, in <module>\n    trials=Trials(),notebook_name='Best',rseed=1)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\", line 42, in minimize\n    notebook_name=notebook_name, verbose=verbose)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\", line 90, in base_minimizer\n    rstate=np.random.RandomState(rseed))\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\", line 307, in fmin\n    return_argmin=return_argmin,\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\base.py\", line 635, in fmin\n    return_argmin=return_argmin)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\", line 320, in fmin\n    rval.exhaust()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\", line 199, in exhaust\n    self.run(self.max_evals - n_done, block_until_done=self.async)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\", line 173, in run\n    self.serial_evaluate()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\", line 92, in serial_evaluate\n    result = self.domain.evaluate(spec, ctrl)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\base.py\", line 840, in evaluate\n    rval = self.fn(pyll_rval)\n  File \"C:\\Users\\Simas\\Desktop\\Kaggle\\Movie Sentiment\\temp_model.py\", line 131, in keras_fmin_fnct\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\models.py\", line 845, in fit\n    initial_epoch=initial_epoch)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\engine\\training.py\", line 1457, in fit\n    self._make_train_function()\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\engine\\training.py\", line 1001, in _make_train_function\n    self.total_loss)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\optimizers.py\", line 197, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\optimizers.py\", line 47, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2108, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 560, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 368, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 560, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\", line 426, in _TransposeGrad\n    return [array_ops.transpose(grad, array_ops.invert_permutation(p)), None]\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1270, in transpose\n    ret = gen_array_ops.transpose(a, perm, name=name)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3721, in transpose\n    result = _op_def_lib.apply_op(\"Transpose\", x=x, perm=perm, name=name)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'lstm_70/transpose', defined at:\n  File \"C:\\Python\\Python35\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 28 identical lines from previous traceback]\n  File \"C:\\Python\\Python35\\lib\\site-packages\\hyperopt\\base.py\", line 840, in evaluate\n    rval = self.fn(pyll_rval)\n  File \"C:\\Users\\Simas\\Desktop\\Kaggle\\Movie Sentiment\\temp_model.py\", line 119, in keras_fmin_fnct\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\models.py\", line 455, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 252, in __call__\n    return super(Recurrent, self).__call__(inputs, **kwargs)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\engine\\topology.py\", line 554, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 298, in call\n    input_length=input_shape[1])\n  File \"C:\\Python\\Python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2178, in rnn\n    inputs = tf.transpose(inputs, (axes))\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1270, in transpose\n    ret = gen_array_ops.transpose(a, perm, name=name)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3721, in transpose\n    result = _op_def_lib.apply_op(\"Transpose\", x=x, perm=perm, name=name)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[128,49,2048]\n\t [[Node: gradients_69/lstm_70/transpose_grad/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _class=[\"loc:@lstm_70/transpose\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_69/lstm_70/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3, gradients_69/lstm_70/transpose_grad/InvertPermutation)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_run, best_model = optim.minimize(model=model, data=data, algo=tpe.suggest, max_evals = 100, \n",
    "                                      trials=Trials(),notebook_name='Best',rseed=1)\n",
    "\n",
    "\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156032/156060 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.73919014618455725, 0.69364987826035696]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'recurrent_dropout': 0.3849339446151476, 'LSTM_1': 1, 'batch_size': 1, 'lstm_dropout': 0.0067245252545650724, 'dense_dropout_2': 0.4151995061036438, 'LSTM': 1, 'optimizer': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3 epoch val_acc: 0.629\n",
    "bp629 = {'LSTM': 128, 'Dense': 256, 'optimizer': 'rmsprop', 'recurrent_dropout': 0.2, 'batch_size': 128, 'lstm_dropout': 0.2, 'dense_dropout': 0.2}\n",
    "bm629 = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/4\n",
      "124848/124848 [==============================] - 223s - loss: 0.7863 - acc: 0.6754 - val_loss: 0.9202 - val_acc: 0.6241\n",
      "Epoch 2/4\n",
      "124848/124848 [==============================] - 217s - loss: 0.7506 - acc: 0.6917 - val_loss: 0.9140 - val_acc: 0.6231\n",
      "Epoch 3/4\n",
      "124848/124848 [==============================] - 217s - loss: 0.7249 - acc: 0.7015 - val_loss: 0.9201 - val_acc: 0.6290\n",
      "Epoch 4/4\n",
      "124848/124848 [==============================] - 219s - loss: 0.7040 - acc: 0.7116 - val_loss: 0.9268 - val_acc: 0.6242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15627c43e10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(x, y, batch_size=128, epochs=4, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'recurrent_dropout': 0.0, 'LSTM_1': 512, 'recurrent_dropout_1': 0.1, 'optimizer': 'adam', 'LSTM': 512, 'Dropout': 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/4\n",
      "124848/124848 [==============================] - 772s - loss: 0.6935 - acc: 0.7082 - val_loss: 0.9363 - val_acc: 0.6204\n",
      "Epoch 2/4\n",
      "124848/124848 [==============================] - 767s - loss: 0.6453 - acc: 0.7277 - val_loss: 0.9444 - val_acc: 0.6255\n",
      "Epoch 3/4\n",
      "124848/124848 [==============================] - 770s - loss: 0.6051 - acc: 0.7419 - val_loss: 0.9762 - val_acc: 0.6217\n",
      "Epoch 4/4\n",
      "124848/124848 [==============================] - 756s - loss: 0.5673 - acc: 0.7548 - val_loss: 1.0209 - val_acc: 0.6183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f72d299b70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(x, y, batch_size=128, epochs=4, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
